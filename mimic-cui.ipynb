{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cui2Vec on MIMIC Notes\n",
    "\n",
    "This project is to grab the CUIs of each concept identified in a given MIMIC note using [QuickUMLS ](https://github.com/Georgetown-IR-Lab/QuickUMLS) and use the [pre-trained CUI embeddings](https://figshare.com/s/00d69861786cd0156d81) to get an embedding that represents the note for all MIMIC notes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "import psycopg2\n",
    "\n",
    "from collections import OrderedDict\n",
    "from pathlib import Path\n",
    "from QuickUMLS.quickumls import QuickUMLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('data')\n",
    "QUMLS_PATH = Path('/storage/UMLS-Storage/quickumls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_len(l):\n",
    "    return sum([len(sl) for sl in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'start': 117,\n",
       "  'end': 132,\n",
       "  'ngram': 'type 2 diabetes',\n",
       "  'term': 'type 2 diabetes',\n",
       "  'cui': 'C0011860',\n",
       "  'similarity': 1.0,\n",
       "  'semtypes': {'T047'},\n",
       "  'preferred': 1},\n",
       " {'start': 117,\n",
       "  'end': 132,\n",
       "  'ngram': 'type 2 diabetes',\n",
       "  'term': 'type diabetes',\n",
       "  'cui': 'C1320657',\n",
       "  'similarity': 0.8362420100070908,\n",
       "  'semtypes': {'T033'},\n",
       "  'preferred': 1}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`QuickUMLS` returns a **list of list of dicts**:\n",
    "1. Outer list holds all the concepts that were found in the note\n",
    "2. Interlist contains all the *variations* of a single concept that QuickUMLS found\n",
    "3. Each dictionary contains information about the concept itself with the following keys:\n",
    "    * start: starting position of the concept in the note\n",
    "    * end: ending position of the concept in the note\n",
    "    * ngram: the group of words that were used to identify the concept. This value is <= $window_size$ param of the matcher. **All the dictionary within an innerlist have the same ngram**.\n",
    "    * term: all the variations within the ngram words that are individual medical concepts with their own CUIs. For example with ngram \"type 2 diabetes\" we get terms \"type 2 diabetes\" and \"type diabetes\" each with its own CUI. **The innerlist contains dicts with different term keys**.\n",
    "    * cui: The CUI of the concept\n",
    "    * similarity: Similarity measure based on metric of the matcher (jaccard, dice, cosine). This value is >= $threshold$ param of the matcher\n",
    "    * semtypes\n",
    "    * preferred\n",
    "\n",
    "The pre-trained CUI vectors are of size 500. The basic idea is to represent each note with a 500-dimension vector that captures the unique medical concepts pertaining to that note by combining these pre-trained vectors. Not all the CUIs returned by the matcher are found in the pre-trained vector list. For those that are not found, I just discard them. This is how the combination is done:\n",
    "1. First the matcher is defined and the note is run through the matcher\n",
    "2. If there are no matches found, then just return a 500-dimension zero vector\n",
    "3. Initialize two dictionaries: \n",
    "    1. to hold the counts of the CUIs found in the matcher (for final weighted averaging) $ngram\\_counts$\n",
    "    2. to hold the average CUI of a given ngram concept $ngram\\_vecs$\n",
    "4. Iterate over the matches and grab the ngram (the outer list)\n",
    "5. If its already present in $ngram\\_vecs$, we've seen it before, so just update the count and continue\n",
    "6. If not, initilize a variable to hold the number of valid cuis $n\\_valid\\_cuis$ (i.e., CUIs for which we have a pre-trained vector available) and 500-dimension zero vector to hold the average $cui\\_avg$\n",
    "7. Iterate of all the matched CUIs (inner list) and check if the current CUI is valid\n",
    "8. If it is then increment $n\\_valid\\_cuis$ and grab the vector from the pre-trained vector for the current CUI and add it to $cui\\_avg$\n",
    "9. If we have valid CUIS, then set the count of the CUI to 1 and compute the average from the sum created in the previous step\n",
    "10. Convert both the counts and average vectors into numpy arrays\n",
    "11. Use numpy's `average` method to compute the weighted average of the concept whereby repeated concepts receive a higher weight (count)\n",
    "12. Return the resulting 500-dimension vector that would represent the note\n",
    "\n",
    "Downfalls:\n",
    "1. Negations are not taken into account. Thus if there are concepts that repeated many times but are negated it will still receive a higher weight which could lead to problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cuivec(matches):    \n",
    "    if not matches:\n",
    "        return np.zeros(cui_emb_sz)\n",
    "    \n",
    "    ngram_counts = OrderedDict()\n",
    "    ngram_vecs = OrderedDict()\n",
    "\n",
    "    for cs in matches:\n",
    "        ngram = cs[0]['ngram']\n",
    "        if ngram in ngram_vecs:\n",
    "            ngram_counts[ngram] += 1\n",
    "            continue\n",
    "        n_valid_cuis = 0\n",
    "        cui_avg = np.zeros(cui_emb_sz)\n",
    "        for c in cs:\n",
    "            if c['cui'] in cui2idx:\n",
    "                n_valid_cuis += 1\n",
    "                cui_avg += cui_vecs[cui2idx[c['cui']]]\n",
    "        if n_valid_cuis != 0:\n",
    "            ngram_counts[ngram] = 1\n",
    "            ngram_vecs[ngram] = cui_avg / n_valid_cuis\n",
    "    \n",
    "    weights = np.array(list(ngram_counts.values()))\n",
    "    vectors = np.array(list(ngram_vecs.values()))         \n",
    "    return np.average(vectors, axis=0, weights=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and save pre-trained CUI Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cui_vecs_df = pd.read_csv('/storage/pre-trained/cui2vec_pretrained.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2cui = cui_vecs_df['cui'].to_dict()\n",
    "cui_vecs = cui_vecs_df.loc[:, cui_vecs_df.columns != 'cui'].values\n",
    "\n",
    "pickle.dump(idx2cui, open(PATH/'idx2cui.pkl', 'wb'))\n",
    "np.save(PATH/'cui-vecs.npy', cui_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract CUIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2cui = pickle.load(open(PATH/'idx2cui.pkl', 'rb'))\n",
    "cui2idx = {c: i for i, c in idx2cui.items()}\n",
    "\n",
    "cui_vecs = np.load(PATH/'cui-vecs.npy')\n",
    "cui_emb_sz = cui_vecs.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "qu = QuickUMLS(QUMLS_PATH, threshold=0.8, similarity_name='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_note = \"The patient showed symtoms of hypertension. No evidence of heart attack but patient had cardiac arrest. He developed type 2 diabetes. But maybe cardiac arrest later with heart attack.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 27, 3.0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = qu.match(test_note, best_match=True, ignore_syntax=False)\n",
    "l = len(matches)\n",
    "tl = total_len(matches)\n",
    "if l:\n",
    "    al = tl/l\n",
    "else:\n",
    "    al = 0\n",
    "l, tl, al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = get_cuivec(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_note = '''\n",
    "Joseph R. Smith\n",
    "\n",
    "1234567-8\n",
    "\n",
    "4/5/2006\n",
    "\n",
    "REASON FOR VISIT:Here to get a new primary care physician.\n",
    "\n",
    "HPI: Mr. Smith is a 56-year-old gentleman formally followed at Carolina Premier who presents to obtain a new primary care physician secondary to insurance changes. He has a past medical history significant for a myocardial infarction in 1994. His cholesterol has been fine. Catheterization showed a possible \"kink\" in one of his vessels and it was thought that he had a possible \"eddy\" of current which led to a clot. He has been on Coumadin since then as well as a calcium channel blocker with the thought that there may have been a superimposed spasm. He has had several unremarkable stress tests since then. He works out on a Nordic-Track three times a week without any chest pain or shortness of breath. He has a history of possible peptic ulcer disease in 1981. He was treated with H2 blockers and his symptoms resolved. He has never had any bleeding to his knowledge. He had a hernia repair bilaterally in 1989 and surgery for a right knee cyst in 1999, all of which went well. He also has about a year long history of right buttock pain. This happens only when he is sitting for some time and does not change position. It does not happen when he is walking or exercising. He wonders if it might be pyriformis syndrome. If he changes positions frequently or stretches his legs, this seems to help. He has no acute complaints today and is here to get plugged into the system. He does wonder if there is anything else that can be done about his buttock pain.\n",
    "\n",
    "PAST MEDICAL HISTORY: As above. In addition, he had a flexible sigmoidoscopy in 2003 which was okay.\n",
    "\n",
    "MEDICATIONS: Tylenol p.r.n., baby aspirin p.o. q.d., Coumadin 3.5 mg p.o. q.d., Adalat Time Released tablets 30 mg one p.o. q.d., multivitamin, glucosamine and chondroitin sulfate.\n",
    "\n",
    "ALLERGIES: No Known Drug Allergies\n",
    "\n",
    "FAMILY HISTORY: His mother had diabetes developed at age 55 and coronary artery disease in her mid sixties. His father had CAD as well but not until his 70s. A paternal aunt had breast cancer. There is no history of colon or prostate cancer.\n",
    "\n",
    "SOCIAL HISTORY: He lives in Durham with his wife and mother. He works for a biotech company. He does not smoke. He drinks two beers per night and reports no trouble with alcohol in the past. No history of drug use.\n",
    "\n",
    "REVIEW OF SYSTEMS: As per his personal health summary and is significant only for his buttock pain as listed above, but is otherwise essentially unremarkable.\n",
    "\n",
    "PHYSICAL EXAM:\n",
    "\n",
    "VITAL SIGNS: Weight 175.2 pounds which is 79.3 kg, blood pressure 142/96 by the nurse, 140/92 by me, pulse is 64.\n",
    "\n",
    "GENERAL: A healthy-appearing middle-aged gentleman.\n",
    "\n",
    "HEENT: Pupils equal, round, reactive to light. Conjunctivaepink. Sclerae anicteric. Tympanic membranes clear. Oropharynx clear.\n",
    "\n",
    "NECK: No lymphadenopathy or thyromegaly or JVD.\n",
    "\n",
    "LUNGS: Clear to auscultation and percussion.\n",
    "\n",
    "HEART: Regular rate and rhythm without murmur, rub, or gallop.\n",
    "\n",
    "ABDOMEN: Normal bowel sounds. Soft, nontender. No hepatosplenomegaly.\n",
    "\n",
    "EXTREMITIES: No cyanosis, clubbing, or edema. 2+ peripheral pulses.\n",
    "\n",
    "NEUROLOGIC: Motor and sensation grossly intact.\n",
    "\n",
    "PSYCHIATRIC: Normal affect and behavior.\n",
    "\n",
    "DERMATOLOGIC: He has a small whitish papule at the upper borderof his mustache on the left.\n",
    "\n",
    "MUSCULOSKELETAL: Full range of motion of his legs and hips bilaterally with no tenderness to palpation over his buttocks.\n",
    "\n",
    "ASSESSMENT/PLAN:\n",
    "\n",
    "Status post myocardial infarction. No evidence for actual CAD. He will continue his aspirin and Coumadin. Unclear to exactly how long he should be on Coumadin or if this is really needed. At some point, may discuss this with cardiology. We will check an INR today and get him plugged into our Coumadin clinic. Check cholesterol.\n",
    "High blood pressure. He will continue with diet and exercise changes. At next visit, may go up on his calcium channel blocker versus add another agent. Check creatinine and potassium today.\n",
    "Buttock pain. Will try some physical therapy.\n",
    "Will send him to dermatology for the papule above his mustache.\n",
    "Possible h/o peptic ulcer disease. As he has not had any known GI bleed, do not feel a need to check H. pylori serology today.\n",
    "Health maintenance. Tetanus shot today. Flex sig as above. Will discuss prostate cancer screening next visit.\n",
    "Return to clinic in four months.\n",
    "John Student, MS3\n",
    "\n",
    "Seen with Joe Doctor, MD\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab sample data from MIMIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-18T23:05:14.536531Z",
     "start_time": "2018-03-18T23:04:17.500997Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cats = pd.read_csv('cats.csv')\n",
    "max_limit = 5\n",
    "\n",
    "queries = []\n",
    "for category, n_notes in zip(cats['category'], cats['number_of_notes']):\n",
    "    limit = min(max_limit, n_notes) if max_limit > 0 else n_notes\n",
    "    if limit == max_limit:\n",
    "        q = f\"\"\"\n",
    "        select category, text from correctnotes where category=\\'{category}\\' order by random() limit {limit};\n",
    "        \"\"\"\n",
    "    else:\n",
    "        q = f\"\"\"\n",
    "        select category, text from correctnotes where category=\\'{category}\\';\n",
    "        \"\"\"\n",
    "    queries.append(q)\n",
    "\n",
    "dfs = []\n",
    "\n",
    "con = psycopg2.connect(dbname='mimic', user='sudarshan', host='/var/run/postgresql')\n",
    "for q in queries:\n",
    "    df = pd.read_sql_query(q, con)\n",
    "    dfs.append(df)\n",
    "con.close()\n",
    "    \n",
    "df = pd.concat(dfs)\n",
    "# df.set_index('row_id', inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pyContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to encode domain knowledge in the modifiers and targets for using pyContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyConTextNLP.pyConText as pyConText\n",
    "import pyConTextNLP.itemData as itemData\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modifiers = itemData.get_items(\n",
    "    \"https://raw.githubusercontent.com/chapmanbe/pyConTextNLP/master/KB/lexical_kb_05042016.yml\")\n",
    "targets = itemData.get_items(\n",
    "    \"https://raw.githubusercontent.com/chapmanbe/pyConTextNLP/master/KB/utah_crit.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markup = pyConText.ConTextMarkup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markup.setRawText(test_note.lower())\n",
    "markup.cleanText()\n",
    "markup.markItems(modifiers, mode='modifier')\n",
    "markup.markItems(targets, mode='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in markup.nodes(data=True):\n",
    "    print(node)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
