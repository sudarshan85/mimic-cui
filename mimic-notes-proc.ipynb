{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIMIC Notes Pre-Processing\n",
    "\n",
    "Pre-processing MIMIC notes for language model and CUIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a list of redacted items with an example and the replacement token.\n",
    "\n",
    "Redacted items:\n",
    "* [x] First Name: `[**First Name (Titles) 137**]`, `xxname`\n",
    "* [x] Last Name: `[**Last Name (Titles) **]`, `xxln`\n",
    "* [x] Initials: `[**Initials (NamePattern4) **]`, `xxinit`\n",
    "* [x] Name: `[**Name (NI) **]`, `xxname`\n",
    "* [x] Doctor First Name: `[**Doctor First Name 1266**]`, `xxdocfn`\n",
    "* [x] Doctor Last Name: `[**Doctor Last Name 1266**]`, `xxdocln`\n",
    "* [x] Known Last Name: `[**Known lastname 658**]`, `xxln`\n",
    "* [x] Hospital: `[**Hospital1 **]`, `xxhosp`\n",
    "* [x] Hospital Unit Name: `**Hospital Unit Name 10**`, `xxhosp`\n",
    "* [x] Company: `[**Company 12924**]`, `xxwork`\n",
    "* [x] University/College: `[**University/College **]`, `xxwork`\n",
    "* [x] Date of format YYYY-M-DD: `[**2112-4-18**]`, `xxdate`\n",
    "* [x] Year: `[**Year (4 digits) **]`, `xxyear`\n",
    "* [x] Year YYYY format: `[**2119**]`, `xxyear` - I use a regex `\\b\\d{4}\\b` that will match **any** 4 digits which might be problematic, but for the most part 4 digits by itself seems to indicate a year.\n",
    "* [x] Date of format M-DD: `[**6-12**]`, `[**12/2151**]`, `xxmmdd`\n",
    "* [x] Month/Day: `[**Month/Day (2) 509**]`, `xxmmdd`\n",
    "* [x] Month (only): `[**Month (only) 51**]`, `xxmonth`\n",
    "* [x] Holiday: `[**Holiday 3470**]`, `xxhols`\n",
    "* [x] Date Range: `[**Date range (1) 7610**]`, `xxdtrnge`\n",
    "* [x] Country: `[**Country 9958**]`, `xxcntry`\n",
    "* [x] State: `[**State 3283**]`, `xxstate`\n",
    "* [x] Location: `**Location (un) 2432**`, `xxloc`\n",
    "* [x] Telephone/Fax: `[**Telephone/Fax (3) 8049**]`, `xxph`\n",
    "* [x] Clip Number: `[**Clip Number (Radiology) 29923**]`, `xxradclip`\n",
    "* [x] Pager Numeric Identifier: `[**Numeric Identifier 6403**]`, `xxpager`\n",
    "* [x] Pager Number: `[**Pager number 13866**]`, `xxpager`\n",
    "* [x] Social Security Number: `[**Security Number 10198**]`, `xxssn`\n",
    "* [x] Serial Number: `[**Serial Number 3567**]`, `xxsno`\n",
    "* [x] Medical Record Number: `[**Medical Record Number **]`, `xxmrno`\n",
    "* [x] Provider Number: `[**Provider Number 12521**]`, `xxpno`\n",
    "* [x] Age over 90: `[**Age over 90 **]`, `xxage90`\n",
    "* [x] Contact Info: `[**Contact Info **]`, `xxcontact`\n",
    "* [x] Job Number: `[**Job Number **]`, `xxjobno`\n",
    "* [x] Dictator Number: `[**Dictator Info **]`, `xxdict`\n",
    "* [x] Pharmacy MD Number/MD number: `[**Pharmacy MD Number **]`, `xxmdno`\n",
    "* [x] Time: `12:52 PM`, split into 6 segments by the hour and replace with the following tokens: `midnight, dawn, forenoon, afternoon, dusk, night`\n",
    "* 2-digit Numbers: `[** 84 **]`, `xx2digit`\n",
    "* 3-digit Numbers: `[** 834 **]`, `xx3digit`\n",
    "* Wardname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from process_notes import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab sample data from MIMIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-18T23:05:14.536531Z",
     "start_time": "2018-03-18T23:04:17.500997Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cats = pd.read_csv('cats.csv')\n",
    "max_limit = -1\n",
    "\n",
    "queries = []\n",
    "for category, n_notes in zip(cats['category'], cats['number_of_notes']):\n",
    "    limit = min(max_limit, n_notes) if max_limit > 0 else n_notes\n",
    "    if limit == max_limit:\n",
    "        q = f\"\"\"\n",
    "        select * from correctnotes where category=\\'{category}\\' order by random() limit {limit};\n",
    "        \"\"\"\n",
    "    else:\n",
    "        q = f\"\"\"\n",
    "        select * from correctnotes where category=\\'{category}\\';\n",
    "        \"\"\"\n",
    "    queries.append(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-18T23:05:14.536531Z",
     "start_time": "2018-03-18T23:04:17.500997Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "dfs = []\n",
    "\n",
    "con = psycopg2.connect(dbname='mimic', user='sudarshan', host='/var/run/postgresql')\n",
    "for q in queries:\n",
    "    df = pd.read_sql_query(q, con)\n",
    "    dfs.append(df)\n",
    "con.close()\n",
    "    \n",
    "df = pd.concat(dfs)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "# df.set_index('row_id', inplace=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['category', 'text']].groupby(['category']).agg(['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['text'] = df['text'].apply(process_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path/'processed_noteevents.pkl', 'wb') as f:\n",
    "    pickle.dump(df, f)\n",
    "\n",
    "texts = df['text']\n",
    "texts.to_csv(path/'texts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_df = pickle.load(open(path/'processed_noteevents.pkl', 'rb'))\n",
    "sub_df = pd.DataFrame({'text': ori_df['text'], 'category': ori_df['category'], 'description': ori_df['description'], 'labels': [0]*len(ori_df)}, columns=['labels', 'category', 'description', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [sub_df.loc[ori_df['category'] == c] for c in sub_df['category'].unique()]\n",
    "msks = [np.random.rand(len(d)) < 0.9 for d in dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dfs = [None] * len(dfs)\n",
    "val_dfs = [None] * len(dfs)\n",
    "\n",
    "for i in range(len(dfs)):\n",
    "    df = dfs[i]\n",
    "    mask = msks[i]\n",
    "    train_dfs[i] = df[mask]\n",
    "    val_dfs[i] = df[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1874688 1874065 623\n",
      "207606 208229 -623\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.concat(train_dfs)\n",
    "val_df = pd.concat(val_dfs)\n",
    "\n",
    "print(len(train_df), (len(ori_df) - len(ori_df)//10), len(train_df)-(len(ori_df) - len(ori_df)//10))\n",
    "print(len(val_df), (len(ori_df)//10), len(val_df)-(len(ori_df)//10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df[['labels', 'description', 'text']].to_csv(path/'test-texts.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Case Management</th>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consult</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discharge summary</th>\n",
       "      <td>6031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ECG</th>\n",
       "      <td>20688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Echo</th>\n",
       "      <td>4618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>General</th>\n",
       "      <td>865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nursing</th>\n",
       "      <td>22190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nursing/other</th>\n",
       "      <td>81951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nutrition</th>\n",
       "      <td>865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pharmacy</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Physician</th>\n",
       "      <td>14039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Radiology</th>\n",
       "      <td>52243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rehab Services</th>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Respiratory</th>\n",
       "      <td>3183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Social Work</th>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    text\n",
       "                   count\n",
       "category                \n",
       "Case Management      106\n",
       "Consult               11\n",
       "Discharge summary   6031\n",
       "ECG                20688\n",
       "Echo                4618\n",
       "General              865\n",
       "Nursing            22190\n",
       "Nursing/other      81951\n",
       "Nutrition            865\n",
       "Pharmacy               6\n",
       "Physician          14039\n",
       "Radiology          52243\n",
       "Rehab Services       502\n",
       "Respiratory         3183\n",
       "Social Work          308"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df[['category', 'text']].groupby(['category']).agg(['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[['category', 'text']].groupby(['category']).agg(['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_df[['category', 'text']].groupby(['category']).agg(['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "953\n",
      "847 106\n",
      "****\n",
      "98\n",
      "87 11\n",
      "****\n",
      "59652\n",
      "53621 6031\n",
      "****\n",
      "209051\n",
      "188363 20688\n",
      "****\n",
      "45794\n",
      "41176 4618\n",
      "****\n",
      "8236\n",
      "7371 865\n",
      "****\n",
      "223182\n",
      "200992 22190\n",
      "****\n",
      "822497\n",
      "740546 81951\n",
      "****\n",
      "9400\n",
      "8535 865\n",
      "****\n",
      "101\n",
      "95 6\n",
      "****\n",
      "141281\n",
      "127242 14039\n",
      "****\n",
      "522279\n",
      "470036 52243\n",
      "****\n",
      "5408\n",
      "4906 502\n",
      "****\n",
      "31701\n",
      "28518 3183\n",
      "****\n",
      "2661\n",
      "2353 308\n",
      "****\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dfs)):\n",
    "    assert (len(dfs[i]) == len(train_dfs[i])+len(val_dfs[i]))\n",
    "    print(len(dfs[i]))\n",
    "    print(len(train_dfs[i]), len(val_dfs[i]))\n",
    "    print('****')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
